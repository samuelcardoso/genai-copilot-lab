# Workshop ‚Äî Criando um Copilot Personalizado com RAG (Gemini + FAISS)

> **Dura√ß√£o sugerida:** 90‚Äì120 min (pr√°tica guiada)  
> **P√∫blico:** alunos de Engenharia de Software (n√≠vel iniciante/intermedi√°rio em Python)

Este workshop conduz, passo a passo, a constru√ß√£o de um **copilot** que responde perguntas
**com base nas Boas Pr√°ticas da sua empresa** e **no seu c√≥digo-fonte**, usando **RAG** (Retrieval-Augmented Generation),
**Gemini (Google)** para *embeddings* e *gera√ß√£o*, e **FAISS** para busca vetorial.

---

## Objetivos de Aprendizagem

Ao final, o aluno ser√° capaz de:

1. Explicar o fluxo **RAG** (ingest√£o ‚ûú indexa√ß√£o ‚ûú recupera√ß√£o ‚ûú gera√ß√£o).
2. Preparar dados (texto e c√≥digo) e **chunkar** conte√∫do com sobreposi√ß√£o.
3. Gerar **embeddings** com `gemini-embedding-001`.
4. Construir e consultar um √≠ndice **FAISS** (similaridade cosseno via produto interno em vetores normalizados).
5. Montar *prompts* que **citam o contexto recuperado** para o modelo de gera√ß√£o (`gemini-2.5-flash`).
6. Executar um **chat RAG** que ‚Äúcita‚Äù arquivos do c√≥digo nos trechos relevantes.

---

## Pr√©-requisitos

- **Python 3.11+**  
- **Conta Google** com chave **GEMINI_API_KEY** (gratuita para devs/estudantes)
- Conhecimentos b√°sicos de:
  - Terminal/CLI
  - Python (venv, pacotes)
  - Leitura de c√≥digo

---

## Setup do Ambiente (10‚Äì15 min)

> Execute os passos **dentro da pasta** `genai-copilot-lab/`.

1) **Crie o ambiente virtual e instale depend√™ncias**
~~~bash
# op√ß√£o com pyenv-virtualenv
pyenv virtualenv 3.11.11 genai-copilot-lab
pyenv local genai-copilot-lab

# ou venv nativo
python -m venv .venv
# Linux/macOS
source .venv/bin/activate
# Windows (PowerShell):
# .venv\Scripts\Activate.ps1

pip install -r requirements.txt
~~~

2) **Configure o `.env`**  
Crie um arquivo `.env` com o conte√∫do:

~~~dotenv
GEMINI_API_KEY="SUA_CHAVE_AQUI"
# opcionais (defaults j√° definidos no c√≥digo)
# GEMINI_CHAT_MODEL="gemini-2.5-flash"
# GEMINI_EMBED_MODEL="gemini-embedding-001"
~~~

> **Dica:** Se quiser, crie um `.env.example` para os alunos e pe√ßa para copiarem para `.env`.

---

## Estrutura do Projeto (resumo)

~~~text
genai-copilot-lab/
  ‚îú‚îÄ main.py                # CLI do Copilot com RAG (Gemini + FAISS)
  ‚îú‚îÄ README.md
  ‚îú‚îÄ WORKSHOP.md            # (este arquivo)
  ‚îú‚îÄ requirements.txt
  ‚îú‚îÄ .gitignore
  ‚îî‚îÄ (artefatos gerados em runtime)
      bp_faiss.index
      bp_chunks.pkl
      code_faiss.index
      code_chunks.pkl
~~~

---

## Roteiro Pr√°tico (m√£o na massa)

### Passo 0 ‚Äî Sanidade do SDK (opcional, 3 min)

> Se quiser testar rapidamente sua chave antes do RAG:

~~~bash
python - << 'PY'
from google import genai
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
r = client.models.generate_content(model="gemini-2.5-flash", contents="Diga 'ok Gemini' em pt-br.")
print(r.text)
PY
~~~

Se imprimir algo como ‚Äúok Gemini‚Äù, estamos prontos.

---

### Passo 1 ‚Äî Ingest√£o de **Boas Pr√°ticas** (10‚Äì12 min)

1) Crie uma pasta `dados/` e um arquivo `boas_praticas.txt` (ou use o seu documento real):

~~~bash
mkdir -p dados
~~~

Abra `dados/boas_praticas.txt` e cole algo como:

~~~text
# Boas Pr√°ticas ‚Äî Equipe XPTO
1. Logging deve usar n√≠veis apropriados (INFO, WARNING, ERROR).
2. Fun√ß√µes devem ter docstrings claras e tipagem est√°tica sempre que poss√≠vel.
3. Evitar duplica√ß√£o de c√≥digo (DRY). Refatorar fun√ß√µes muito longas.
4. Testes unit√°rios para fun√ß√µes cr√≠ticas; cobertura m√≠nima recomendada: 80%.
5. Configura√ß√µes sens√≠veis via vari√°veis de ambiente (.env), nunca em c√≥digo.
~~~

2) Ingerir o `.txt` no √≠ndice FAISS:

~~~bash
python main.py ingest-best --file ./dados/boas_praticas.txt
~~~

> Sa√≠da esperada: cria√ß√£o de `bp_faiss.index` e `bp_chunks.pkl`.

---

### Passo 2 ‚Äî Ingest√£o de **C√≥digo-Fonte** (12‚Äì15 min)

Voc√™ pode usar **qualquer reposit√≥rio pequeno** ou, para fins de aula, apontar para `genai-tests-lab/` (j√° presente no monorepo):

~~~bash
# exemplo: ingerir apenas .py e .md (padr√£o)
python main.py ingest-code --dir ../genai-tests-lab

# (opcional) especificar extens√µes:
python main.py ingest-code --dir ../genai-tests-lab --ext ".py,.md,.txt"
~~~

> Sa√≠da esperada: cria√ß√£o de `code_faiss.index` e `code_chunks.pkl`.  
> Os *chunks* de c√≥digo s√£o prefixados com `"[FILE]: caminho/arquivo.py"` para que o modelo possa referenciar o arquivo na resposta.

---

### Passo 3 ‚Äî **Chat** RAG (15‚Äì20 min)

Inicie o chat interativo:

~~~bash
python main.py chat
~~~

Fa√ßa perguntas que conectem **regras** √†s **partes do c√≥digo**:

~~~text
>> Nosso logging est√° de acordo com as boas pr√°ticas?
>> Onde h√° fun√ß√µes longas que valem refatora√ß√£o?
>> Quais arquivos mostram aus√™ncia de docstrings?
>> Como garantir 80%+ de cobertura nos m√≥dulos principais?
~~~

> **Como o modelo responde?**  
> - Ele gera respostas **com base ESTRITA** no contexto recuperado.  
> - Ao citar trechos de c√≥digo, ele deve mencionar `[FILE]: ...` com o nome do arquivo que veio do chunk.

Para sair, digite `sair`.

---

### Passo 4 ‚Äî Pergunta √önica (modo r√°pido, 2‚Äì3 min)

~~~bash
python main.py ask --question "O m√≥dulo sum.py segue nossas boas pr√°ticas?"
~~~

√ötil para pipelines ou consultas avulsas.

---

## Entendendo o que acontece por tr√°s

### 1) Chunking
- Os textos (boas pr√°ticas) e arquivos de c√≥digo s√£o **quebrados em janelas** (~1200 chars, *overlap* 200) para melhorar a recupera√ß√£o.
- Cada chunk de c√≥digo recebe um prefixo:  
  `"[FILE]: relativo/para/o/diretorio\n<conteudo do arquivo>"`

### 2) Embeddings
- Cada *chunk* vira um vetor com o modelo `gemini-embedding-001`.
- Todos os vetores s√£o **normalizados** (L2=1) para usar **IndexFlatIP** (produto interno ‚âà cosseno).

### 3) FAISS
- Criamos dois √≠ndices: **Boas Pr√°ticas** e **C√≥digo**.
- Na consulta, transformamos a pergunta em embedding e **recuperamos k** vizinhos de cada √≠ndice.

### 4) Gera√ß√£o (LLM)
- Montamos um *prompt* com:
  - **Contexto de Boas Pr√°ticas** (top-k)
  - **Contexto de C√≥digo** (top-k)
  - **Pergunta do usu√°rio**
- O modelo `gemini-2.5-flash` responde **com base nesses trechos**.
- Se algo **n√£o** estiver no contexto, o modelo √© instru√≠do a **dizer que n√£o sabe**.

---

## Exerc√≠cios Propostos (30‚Äì40 min)

1) **Mapeando viola√ß√µes**  
   - Pergunte: ‚ÄúQuais fun√ß√µes n√£o possuem docstring e por qu√™ isso √© um problema segundo nossas boas pr√°ticas?‚Äù  
   - Esperado: a resposta **cita arquivos** via `[FILE]` e relaciona com as regras do `.txt`.

2) **Plano de refatora√ß√£o**  
   - Pergunte: ‚ÄúListe 3 refatora√ß√µes concretas no c√≥digo que alinham com nossas pr√°ticas.‚Äù  
   - Esperado: passos acion√°veis, men√ß√£o a trechos.

3) **Testabilidade**  
   - Pergunte: ‚ÄúQuais partes do projeto mais se beneficiariam de testes adicionais?‚Äù  
   - Esperado: conex√£o direta com a regra ‚Äú80%+ cobertura‚Äù.

4) **Crie seu pr√≥prio `.txt`**  
   - Altere `boas_praticas.txt` para refletir a cultura da equipe da dupla e **reingira**.  
   - Refa√ßa as perguntas do 1‚Äì3 e compare as diferen√ßas.

---

## Desafios (para al√©m do b√°sico)

1) **Tunar k**  
   - No c√≥digo (`retrieve_contexts`), mude `k_bp`/`k_code` e observe a qualidade das respostas.  
   - Projete perguntas onde **mais contexto** melhora a resposta (e onde **atrapalha**).

2) **Cita√ß√µes marcadas**  
   - Alterar `generate_answer`/`build_prompt` para **enumerar** os chunks usados e **incluir um ‚ÄúRefer√™ncias:‚Äù** no fim da resposta.

3) **Filtros por extens√£o**  
   - Exponha `--ext` de forma mais rica: por exemplo, `.py` recebe *chunking* diferente de `.md`.

4) **Paralelizar embeddings**  
   - (Avan√ßado) Fa√ßa *batching* de at√© N textos por chamada de `embed_content` (se o SDK oferecer).

5) **Interface Web**  
   - Crie um *frontend* m√≠nimo (Flask/FastAPI + HTMX) que conversa com as mesmas fun√ß√µes.

---

## Troubleshooting (FAQ r√°pido)

- **`GEMINI_API_KEY` faltando**  
  > Verifique `.env`. Rode `python -c "import os;print(bool(os.getenv('GEMINI_API_KEY')))"`.

- **`faiss` n√£o instala**  
  > Use `faiss-cpu` (j√° no `requirements.txt`). Em alguns ambientes Windows, √© mais simples usar WSL/conda.

- **`RuntimeError: Formato inesperado de retorno de embedding`**  
  > Atualize `google-genai` (`pip install -U google-genai`). O c√≥digo tenta lidar com varia√ß√µes de estrutura; se mudar novamente, ajuste `extract_embedding`.

- **Dimens√£o inconsistente no √≠ndice**  
  > Remova artefatos e reingira:  
  > `python main.py reset` ‚ûú `ingest-best` ‚ûú `ingest-code`.

- **Respostas ‚Äúalucinadas‚Äù**  
  > O prompt instrui a dizer ‚Äún√£o sei‚Äù. Se persistir, reduza `k`, melhore as pr√°ticas no `.txt`, ou torne as perguntas mais espec√≠ficas.

---

## Gloss√°rio R√°pido

- **RAG:** Recupera contexto relevante do seu *corpus* (base pr√≥pria) e injeta no *prompt* antes de gerar a resposta.
- **Embedding:** Vetor num√©rico que ‚Äúrepresenta‚Äù um texto; textos parecidos ‚Üí vetores pr√≥ximos.
- **FAISS:** Biblioteca de busca vetorial eficiente (Facebook AI Similarity Search).
- **Chunk:** Peda√ßo de texto/c√≥digo menor para indexa√ß√£o e recupera√ß√£o.

---

## Encerramento

- Mostre 2‚Äì3 perguntas onde o copilot realmente **aponta para arquivos** e **conecta com a pr√°tica**.
- Discuta limita√ß√µes: **contexto curto**, **‚Äúalucina√ß√µes‚Äù**, **limpeza de dados**, **privacidade**.
- Pr√≥ximos passos: **cita√ß√µes com score**, **reranking**, **UI web**, **observabilidade de prompts**.

> **Atalho √∫til**: se algo der muito errado, rode `python main.py reset` e recomece da ingest√£o.  
> Bom workshop! üöÄ
